{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bit33a9ca7b936a4aca9650369ae0c8d594",
   "display_name": "Python 3.8.5 64-bit",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy.random as rand\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "68636 29413\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')[:-1]\n",
    "print(len(train_data), len(test_data))\n",
    "\n",
    "train_copy = train_data\n",
    "test_copy = test_data.apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_copy.drop(\"class\", axis=1)\n",
    "X = (X-X.mean())/X.std()\n",
    "train_copy = X.join(train_copy[\"class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = test_copy.drop(\"class\", axis=1)\n",
    "X = (X-X.mean())/X.std()\n",
    "test_copy = X.join(test_copy[\"class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(data):\n",
    "    X = data.drop(\"class\", axis = 1)\n",
    "    X = (X-X.mean())/X.std()\n",
    "    X = X.join(data[\"class\"])\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_f(input,expected,typ='quad'):\n",
    "    if len(input) != len(expected):\n",
    "        raise TypeError(\"Input and Observed have length %s and %s respectively.\"%(len(input),len(output)))\n",
    "    else:\n",
    "        if typ == \"quad\":\n",
    "            C = .5 *np.sum(np.sum((input-expected)**2))\n",
    "    return C\n",
    "\n",
    "def cost_der(input,expected,typ='quad'):\n",
    "    if len(input) != len(expected):\n",
    "        raise TypeError(\"Input and Observed have length %s and %s respectively.\"%(len(input),len(output)))\n",
    "    else:\n",
    "        if typ == \"quad\":\n",
    "            Cd = -0.5 *np.sum(np.sum((input-expected)**1))\n",
    "    return Cd\n",
    "\n",
    "def act_f(weight,input,typ = \"sigmoid\"):\n",
    "     if len(weight) != len(input):\n",
    "         raise TypeError(\"Input and Weight have length %s and %s respectively.\"%(len(input),len(weight)))\n",
    "     else:\n",
    "         xw=np.dot(x,w)\n",
    "         if typ == \"sigmoid\":\n",
    "             A = 1/(1 + exp(-xw))\n",
    "         if typ == \"relu\":\n",
    "             A = np.amax([0,xw])\n",
    "     return A\n",
    "\n",
    "def act_der(weight,input,typ = \"sigmoid\"):\n",
    "    if len(weight) != len(input):\n",
    "         raise TypeError(\"Input and Weight have length %s and %s respectively.\"%(len(input),len(weight)))\n",
    "    else:\n",
    "         xw=np.dot(x,w)\n",
    "         if typ == \"sigmoid\":\n",
    "             Ad = 1/(1 + exp(-xw))\n",
    "             Ad = (1- Ad)*Ad\n",
    "         if typ == \"relu\":\n",
    "             if xw > 0:\n",
    "                 Ad = 1\n",
    "             if xw <=0:\n",
    "                 Ad = 0\n",
    "    return Ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_weights(weights,n_i,n_hd,n_n,n_o = 1):\n",
    "    \"\"\"n_i = number of inputs\n",
    "       n_hd = number of hidden layers\n",
    "       n_n = number of nodes per hidden layer\n",
    "       n_o = number of nodes in the output layer\n",
    "       Seed Random uniform weights.\n",
    "    \"\"\"\n",
    "    l_lim = -sqrt(6/(n_i + n_n))\n",
    "\n",
    "    if shape(weights) == (1,0):\n",
    "        weights = [rand.uniform(l_lim,-l_lim,(n_i+1,n_n)),\n",
    "                   rand.uniform(-l_lim,-l_lim,(n_n+1,n_n)) * (n_hd-1) ,\n",
    "                   rand.uniform(-l_lim,-l_lim,(n_n+1,n_o))]\n",
    "    else:\n",
    "        raise TypeError(\"Shape of weight is %s and already exists.\"%(weights.shape))\n",
    "    \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_output(n_i,n_hd,n_n,n_o =1):\n",
    "    \"\"\"n_i = number of inputs\n",
    "       n_hd = number of hidden layers\n",
    "       n_n = number of nodes per hidden layer\n",
    "       n_o = number of nodes in the output layer\n",
    "       the zeroth layer is the output of the first hidden layer\n",
    "\n",
    "    \"\"\"\n",
    "    # The last layer has n_n but we will update onth the zeroth element and forget all the rest.\n",
    "    outputs = np.ones((n_hd+1,n_n))\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_output_der(n_i,n_hd,n_n,n_o =1):\n",
    "    \"\"\"n_i = number of inputs\n",
    "       n_hd = number of hidden layers\n",
    "       n_n = number of nodes per hidden layer\n",
    "       n_o = number of nodes in the output layer\n",
    "       the zeroth layer is the output of the first hidden layer\n",
    "\n",
    "    \"\"\"\n",
    "    # The last layer has n_n but we will update onth the zeroth element and forget all the rest.\n",
    "    output_der = np.ones((n_hd+1,n_n))\n",
    "\n",
    "    return output_der"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_outputs():\n",
    "    \n",
    "    #in this function zeroth layer( the variable) corresponds to the output of the first hidden layer \n",
    "    outputs_loc = outputs_global[-1]\n",
    "    R = [[0] for i in range(n_hd +1)]\n",
    "    for d in range(len(data)):\n",
    "\n",
    "        for layer in range(n_hd+1):\n",
    "            for node in range(n_n):\n",
    "                if layer == 0:\n",
    "                    x = np.array(data[d])\n",
    "                else:                    \n",
    "                    x = outputs_loc[layer][:]\n",
    "                x = np.append([1])\n",
    "                w = weights[layer-1][:][node]\n",
    "                outputs_loc[layer][node] = act_f(w,x)\n",
    "                output_der[layer][node] =act_der(w,x)\n",
    "        outputs_global = # code to append the entire updated output matrix at the bottom of outputs_global using np.split\n",
    "        #now we caclulate derivative of cost function with respect to weights for every data point and then sum it and then store it in the list R define at the beginning of the function.\n",
    "        for layer in range(n_hd+1,0,-1):\n",
    "            for node in range(n_n):\n",
    "                if layer == n_hd +1:\n",
    "                    break\n",
    "                else:\n",
    "                    \n",
    "                    "
   ]
  }
 ]
}